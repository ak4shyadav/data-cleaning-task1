{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d3ad6a",
   "metadata": {},
   "source": [
    "# 📊 Data Cleaning & Preprocessing – Internship Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa352be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Step 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Step 2: Load the Dataset\n",
    "# 👉 Replace the path and filename below with your actual file name\n",
    "file_path = r\"C:/Users/ron33/Downloads/netflix_titles.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 👀 Preview the Data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccfa1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Step 3: Explore the Data\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nColumn names:\\n\", df.columns)\n",
    "print(\"\\nInfo:\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf65317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ❌ Step 4: Check for Missing Values\n",
    "missing = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 Step 5: Handle Missing Values\n",
    "\n",
    "# Example: Fill missing 'director' with 'Unknown'\n",
    "df['director'] = df['director'].fillna('Unknown')\n",
    "\n",
    "# Drop rows where essential columns are missing\n",
    "df = df.dropna(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔁 Step 6: Remove Duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", duplicates)\n",
    "\n",
    "# Remove them\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠 Step 7: Standardize Columns and Values\n",
    "\n",
    "# Rename column headers to lowercase and replace spaces with underscores\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Example: Standardize 'type' column values (just for demo)\n",
    "df['type'] = df['type'].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695cdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🗓 Step 8: Convert Date Columns\n",
    "df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')  # handle invalid dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Step 9: Check Data Types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee40a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💾 Step 10: Save Cleaned Data\n",
    "df.to_csv(\"cleaned_netflix_data.csv\", index=False)\n",
    "print(\"Cleaned dataset saved successfully!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
